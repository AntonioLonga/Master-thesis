{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from spektral.datasets import delaunay\n",
    "from spektral.layers import GraphConv, GlobalAttentionPool\n",
    "from spektral.utils import localpooling_filter\n",
    "from spektral.utils.logging import init_logging\n",
    "\n",
    "\n",
    "from networkx import nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "adj, x, y= delaunay.generate_data(return_type='numpy', classes=[0, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = x.shape[-2]           # Number of nodes in the graphs\n",
    "F = x.shape[-1]           # Original feature dimensionality\n",
    "n_classes = y.shape[-1]   # Number of classes\n",
    "l2_reg = 5e-4             # Regularization rate for l2\n",
    "learning_rate = 1e-3      # Learning rate for Adam\n",
    "epochs = 20               # Number of training epochs\n",
    "batch_size = 32           # Batch size\n",
    "es_patience = 10          # Patience fot early stopping\n",
    "log_dir = init_logging() # Create log directory and file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2       , 0.2236068 , 0.2       , ..., 0.2236068 ,\n",
       "         0.18257419, 0.        ],\n",
       "        [0.2236068 , 0.25      , 0.2236068 , ..., 0.        ,\n",
       "         0.        , 0.2236068 ],\n",
       "        [0.2       , 0.2236068 , 0.2       , ..., 0.        ,\n",
       "         0.18257419, 0.2       ],\n",
       "        ...,\n",
       "        [0.2236068 , 0.        , 0.        , ..., 0.25      ,\n",
       "         0.20412415, 0.        ],\n",
       "        [0.18257419, 0.        , 0.18257419, ..., 0.20412415,\n",
       "         0.16666667, 0.18257419],\n",
       "        [0.        , 0.2236068 , 0.2       , ..., 0.        ,\n",
       "         0.18257419, 0.2       ]],\n",
       "\n",
       "       [[0.33333333, 0.        , 0.25819889, ..., 0.        ,\n",
       "         0.23570226, 0.        ],\n",
       "        [0.        , 0.2       , 0.2       , ..., 0.        ,\n",
       "         0.18257419, 0.2236068 ],\n",
       "        [0.25819889, 0.2       , 0.2       , ..., 0.        ,\n",
       "         0.18257419, 0.2236068 ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.33333333,\n",
       "         0.23570226, 0.        ],\n",
       "        [0.23570226, 0.18257419, 0.18257419, ..., 0.23570226,\n",
       "         0.16666667, 0.        ],\n",
       "        [0.        , 0.2236068 , 0.2236068 , ..., 0.        ,\n",
       "         0.        , 0.25      ]],\n",
       "\n",
       "       [[0.25      , 0.        , 0.2236068 , ..., 0.25      ,\n",
       "         0.20412415, 0.        ],\n",
       "        [0.        , 0.2       , 0.2       , ..., 0.        ,\n",
       "         0.18257419, 0.2236068 ],\n",
       "        [0.2236068 , 0.2       , 0.2       , ..., 0.        ,\n",
       "         0.18257419, 0.2236068 ],\n",
       "        ...,\n",
       "        [0.25      , 0.        , 0.        , ..., 0.25      ,\n",
       "         0.20412415, 0.        ],\n",
       "        [0.20412415, 0.18257419, 0.18257419, ..., 0.20412415,\n",
       "         0.16666667, 0.        ],\n",
       "        [0.        , 0.2236068 , 0.2236068 , ..., 0.        ,\n",
       "         0.        , 0.25      ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.25      , 0.2236068 , 0.20412415, ..., 0.20412415,\n",
       "         0.        , 0.        ],\n",
       "        [0.2236068 , 0.2       , 0.18257419, ..., 0.18257419,\n",
       "         0.        , 0.2       ],\n",
       "        [0.20412415, 0.18257419, 0.16666667, ..., 0.        ,\n",
       "         0.18257419, 0.18257419],\n",
       "        ...,\n",
       "        [0.20412415, 0.18257419, 0.        , ..., 0.16666667,\n",
       "         0.18257419, 0.18257419],\n",
       "        [0.        , 0.        , 0.18257419, ..., 0.18257419,\n",
       "         0.2       , 0.2       ],\n",
       "        [0.        , 0.2       , 0.18257419, ..., 0.18257419,\n",
       "         0.2       , 0.2       ]],\n",
       "\n",
       "       [[0.2       , 0.2236068 , 0.18257419, ..., 0.2       ,\n",
       "         0.        , 0.18257419],\n",
       "        [0.2236068 , 0.25      , 0.20412415, ..., 0.        ,\n",
       "         0.        , 0.20412415],\n",
       "        [0.18257419, 0.20412415, 0.16666667, ..., 0.        ,\n",
       "         0.18257419, 0.16666667],\n",
       "        ...,\n",
       "        [0.2       , 0.        , 0.        , ..., 0.2       ,\n",
       "         0.2       , 0.18257419],\n",
       "        [0.        , 0.        , 0.18257419, ..., 0.2       ,\n",
       "         0.2       , 0.18257419],\n",
       "        [0.18257419, 0.20412415, 0.16666667, ..., 0.18257419,\n",
       "         0.18257419, 0.16666667]],\n",
       "\n",
       "       [[0.25      , 0.2236068 , 0.20412415, ..., 0.20412415,\n",
       "         0.        , 0.        ],\n",
       "        [0.2236068 , 0.2       , 0.18257419, ..., 0.18257419,\n",
       "         0.        , 0.2       ],\n",
       "        [0.20412415, 0.18257419, 0.16666667, ..., 0.        ,\n",
       "         0.18257419, 0.18257419],\n",
       "        ...,\n",
       "        [0.20412415, 0.18257419, 0.        , ..., 0.16666667,\n",
       "         0.18257419, 0.18257419],\n",
       "        [0.        , 0.        , 0.18257419, ..., 0.18257419,\n",
       "         0.2       , 0.2       ],\n",
       "        [0.        , 0.2       , 0.18257419, ..., 0.18257419,\n",
       "         0.2       , 0.2       ]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "fltr = localpooling_filter(adj.copy())\n",
    "fltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "fltr_train, fltr_test, \\\n",
    "x_train, x_test,       \\\n",
    "y_train, y_test = train_test_split(fltr, x, y, test_size=0.1)\n",
    "\n",
    "# Model definition\n",
    "X_in = Input(shape=(N, F))\n",
    "filter_in = Input((N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gc1 = GraphConv(32, activation='relu', kernel_regularizer=l2(l2_reg))([X_in, filter_in])\n",
    "gc2 = GraphConv(32, activation='relu', kernel_regularizer=l2(l2_reg))([gc1, filter_in])\n",
    "pool = GlobalAttentionPool(128)(gc2)\n",
    "\n",
    "output = Dense(n_classes, activation='softmax')(pool)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, filter_in], outputs=output)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "es_callback = EarlyStopping(monitor='val_acc', patience=es_patience)\n",
    "\n",
    "# Train model\n",
    "model.fit([x_train, fltr_train],\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es_callback])\n",
    "\n",
    "# Evaluate model\n",
    "print('Evaluating model.')\n",
    "eval_results = model.evaluate([x_test, fltr_test],\n",
    "                              y_test,\n",
    "                              batch_size=batch_size)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "'Test accuracy: {}'.format(*eval_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
